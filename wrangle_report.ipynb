{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporting the data wrangling efforts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "twitter_archive_enhanced.csv was easy to load into the notebook with a simple `read_csv()`\n",
    "\n",
    "image_predictions.tsv is programatically downloaded with requests and loaded with `read_csv()` too but with the seperator as `\\t` due to it being a tsv file\n",
    "\n",
    "tweet_json.txt was used due to the X API changes which no longer allows free accounts to query tweet information.\n",
    "\n",
    "tweet_json.txt has a json element on each line with the tweet's information, this isn't valid JSON due to 2 reasons:\n",
    "- multiple root elements\n",
    "- no commas seperating these elements\n",
    "\n",
    "What was done to solve this was:\n",
    "- every line was read and put into a list\n",
    "- put every element in a JSON list\n",
    "- join each line with a comma seperator\n",
    "\n",
    "Thanks to pandas, the above was done in less than a second.\n",
    "\n",
    "This transforms our data into valid JSON which pandas can read imported with `read_json()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data was assessed visually and programatically, visually just being scrolling through the document in a non-directed and directed way and programatically being using pandas functions to locate data quality issues and check data types and the values of each column.\n",
    "\n",
    "The program I used to visually assess was Microsoft Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notable functions are:\n",
    "- value_counts()\n",
    "- info()\n",
    "- head()\n",
    "- describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some issues were rare and could only be spotted with visual assessment such as the Snoop Dogg tweet and a very few amount of ratings being incorrect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data was cleaned and tidied up, when new issues were found while cleaning, I would go back to assessment and iterate on the data wrangling process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After each cleaning step, I would go back to the data and assess it again to find more and more issues until I was happy with the quality and tidiness of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data was cleaned with pandas and numpy functions along with some custom functions made specially for this project."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
